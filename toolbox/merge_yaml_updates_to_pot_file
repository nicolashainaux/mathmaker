#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Copyright 2006-2017 Nicolas Hainaux <nh.techn@gmail.com>

# This file is part of Mathmaker.

# Mathmaker is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.

# Mathmaker is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with Mathmaker; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA


# This script is meant to be run from the locale/ directory of the project.

import os
# import re
import sys
import errno
import argparse

import polib
import ruamel.yaml

from mathmaker import settings

settings.init()

# PARSER_COMPLETE = re.compile(
#     r'(^[ ]+\- ([\w]+): \")([\w\d \-\+\'\(\)°\[\]\{\}€<>/:,;!\.\?]+)\"')
# DETECT_UNFINISHED = re.compile(
#     r'(^[ ]+\- ([\w]+): \")([\w\d \-\+\'\(\)°\[\]\{\}€<>/:,;!\.\?]+)\n')
# DETECT_END = re.compile(
#     r'^[ ]+([\w\d \-\+\'\(\)°\[\]\{\}€<>/:,;!\.\?]+)\"')
# PARSER_MULTILINE = re.compile(
#     r'(^[ ]+\- ([\w]+): \")([\w\d \-\+\'\(\)°\[\]\{\}€<>/:,;!\.\?\n]+)\"')

DEFAULT_KEYWORD_STARTS = ['header', 'title', 'text', 'subtitle',
                          'answers_title']
DEFAULT_KEYWORDS = ['wording']
MAIN_POT_FILE_PATH = settings.localedir + 'mathmaker.pot'
PROJECT_ROOT = DIR_TO_BROWSE = settings.rootdir

COLLECTED_STRINGS = {}

# Following code comes from https://stackoverflow.com/a/45717104/3926735


class _Str(ruamel.yaml.scalarstring.ScalarString):
    __slots__ = ('lc')

    style = ""

    def __new__(cls, value):
        return ruamel.yaml.scalarstring.ScalarString.__new__(cls, value)


class _PreservedScalarString(ruamel.yaml.scalarstring.PreservedScalarString):
    __slots__ = ('lc')


class _DoubleQuotedScalarString(ruamel.yaml.scalarstring
                                .DoubleQuotedScalarString):
    __slots__ = ('lc')


class _SingleQuotedScalarString(ruamel.yaml.scalarstring
                                .SingleQuotedScalarString):
    __slots__ = ('lc')


class _Constructor(ruamel.yaml.constructor.RoundTripConstructor):
    def construct_scalar(self, node):
        # type: (Any) -> Any
        if not isinstance(node, ruamel.yaml.nodes.ScalarNode):
            raise ruamel.yaml.constructor.ConstructorError(
                None, None,
                'expected a scalar node, but found %s' % node.id,
                node.start_mark)

        if node.style == '|' and isinstance(node.value,
                                            ruamel.yaml.compat.text_type):
            ret_val = _PreservedScalarString(node.value)
        elif (bool(self._preserve_quotes)
              and isinstance(node.value, ruamel.yaml.compat.text_type)):
            if node.style == "'":
                ret_val = _SingleQuotedScalarString(node.value)
            elif node.style == '"':
                ret_val = _DoubleQuotedScalarString(node.value)
            else:
                ret_val = _Str(node.value)
        else:
            ret_val = _Str(node.value)
        ret_val.lc = ruamel.yaml.comments.LineCol()
        ret_val.lc.line = node.start_mark.line
        ret_val.lc.col = node.start_mark.column
        return ret_val


yaml = ruamel.yaml.YAML()
yaml.Constructor = _Constructor


def collect_strings(data, rel_file_name, keywords_starts, keywords):
    # sys.stderr.write('data={}\ntype={}\n'.format(data, type(data)))
    for key in data:
        # sys.stderr.write('key={}; type={}\n'.format(key, type(key)))
        if isinstance(data, list):
            collect_strings(key, rel_file_name, keywords_starts, keywords)
        elif isinstance(data[key], dict):
            collect_strings(data[key], rel_file_name,
                            keywords_starts, keywords)
        elif isinstance(data[key], list):
            collect_strings(data[key], rel_file_name,
                            keywords_starts, keywords)
        else:
            # sys.stderr.write('data={}\ntype={}\n'.format(data, type(data)))
            # sys.stderr.write('key={}; type={}\n'.format(key, type(key)))
            # sys.stderr.write('data[key]={}\n'.format(data[key]))
            if ((any([key.startswith(k) for k in keywords_starts])
                 or key in keywords)
                and data[key] != ''):
                if not data[key] in COLLECTED_STRINGS:
                    COLLECTED_STRINGS[data[key]] = []
                COLLECTED_STRINGS[data[key]] += \
                    [(rel_file_name, str(data[key].lc.line + 1))]
                # print('{}|{} found in line {}\n'
                #       .format(key, data[key], data[key].lc.line + 1))

    # COLLECTED_STRINGS looks like:
    # {'Something to translate': [("this_file.yaml", 76),
    #                             ("this_other_file.yaml", 34)],
    #  'Something else to translate': [("another_file.yaml", 21)],
    #  etc. }

# ALTERNATE VERSION OF COLLECT STRINGS, WORKING WITH REGEXES, HENCE PROBABLY
# LESS RELIABLE (SHOULD WORK EXCEPT IF SOME CHARACTERS ARE NOT "ALLOWED" IN THE
# REGEX, THAT WOULD LEAD IT NOT TO MATCH CERTAIN LINES)
# THIS REGEX VERSION WORKS ALSO FOR MULTILINE TEXTS
# def collect_strings(filename, rel_file_name, keywords_list):
#     with open(filename) as f:
#         repaired_lines = []
#         unfinished = False
#         add_empty = 0
#         for line in f:
#             if not unfinished:
#                 complete = PARSER_COMPLETE.findall(line)
#                 if complete:
#                     repaired_lines.append(line)
#                 else:
#                     if DETECT_UNFINISHED.findall(line):
#                         unfinished = True
#                     repaired_lines.append(line)
#             else:
#                 repaired_lines[-1] += line
#                 add_empty += 1
#                 if DETECT_END.findall(line):
#                     unfinished = False
#                     for _ in range(add_empty):
#                         repaired_lines.append('')
#                     add_empty = 0
#         for line_nb, line in enumerate(repaired_lines):
#             # sys.stderr.write('\nline n°{}: {}'.format(line_nb + 1, line))
#             matching = PARSER_MULTILINE.findall(line)
#             if matching:
#                 if matching[0][1] in keywords_list:
#                     indent = '\n' + ' ' * (len(matching[0][0]) - 1)
#                     cleaned_up = matching[0][2].replace(indent, '')
#                     # sys.stderr.write('Found: {}\n'.format(cleaned_up))
#                     if (cleaned_up != ''
#                         and cleaned_up not in COLLECTED_STRINGS):
#                         COLLECTED_STRINGS[cleaned_up] = []
#                     if cleaned_up != '':
#                         COLLECTED_STRINGS[cleaned_up] += [(rel_file_name,
#                                                            line_nb + 1)]

    # sys.stderr.write('\nCOLLECTED STRINGS: {}\n'.format(COLLECTED_STRINGS))


def browse_files(path, keyword_starts, keywords_list):
    os.chdir(path)
    file_names = next(os.walk('.'))[2]

    for (file_name, extension) in [os.path.splitext(f) for f in file_names]:
        if extension == '.yaml' and file_name != 'tmp':
            # sys.stderr.write('Browsing {}{}\n'.format(file_name, extension))
            # sys.stdout.write("Checking " + file_name + extension + "\n")
            abspath = os.getcwd() + "/" + file_name + extension
            relpath = abspath[len(PROJECT_ROOT):]
            # collect_strings(file_name + extension, relpath, keywords_list)
            # Below is yaml browsing version
            with open(file_name + extension) as file_path:
                collect_strings(yaml.load(file_path),
                                relpath,
                                keyword_starts,
                                keywords_list)

    for dir_name in next(os.walk('.'))[1]:
        if dir_name != '.git':
            browse_files(dir_name, keyword_starts, keywords_list)

    os.chdir('..')


def main():
    sys.stdout.write('[merge_yaml_updates_to_pot_file] Starting...\n')
    parser = argparse.ArgumentParser(description='Import strings to be '
                                                 'translated from yaml files.')
    parser.add_argument('--potfile', action='store', dest='filename',
                        default=MAIN_POT_FILE_PATH,
                        help='to provide an alternative pot file to process.')
    parser.add_argument('--dirs', action='store', dest='dir_to_browse',
                        nargs='*',
                        default=[DIR_TO_BROWSE],
                        help='to provide other specific directories '
                             'to browse.')
    parser.add_argument('--keywords', action='store', dest='keywords_list',
                        nargs='*', default=DEFAULT_KEYWORDS,
                        help='to provide other keywords.')
    parser.add_argument('--keyword-starts', action='store',
                        dest='keyword_starts',
                        nargs='*', default=DEFAULT_KEYWORD_STARTS,
                        help='to provide other keywords.')
    args = parser.parse_args()

    if not os.path.isfile(args.filename):
        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),
                                args.filename)

    for d in args.dir_to_browse:
        if not os.path.exists(d):
            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), d)

        if not os.path.isdir(d):
            raise NotADirectoryError(errno.ENOTDIR,
                                     os.strerror(errno.ENOTDIR),
                                     d)

    sys.stdout.write('Will look for labels starting with: {}'
                     ' and for labels: {}\n'
                     .format(args.keyword_starts,
                             args.keywords_list))

    for d in args.dir_to_browse:
        browse_files(d, args.keyword_starts, args.keywords_list)

    yaml_pot_file = polib.POFile()
    for sentence in COLLECTED_STRINGS:
        occ = []
        for elt in COLLECTED_STRINGS[sentence]:
            occ += [(elt[0], elt[1])]

        new_entry = polib.POEntry(msgid=sentence, msgstr='', occurrences=occ)
        yaml_pot_file.append(new_entry)

    main_pot_file = polib.pofile(args.filename)
    msgids_from_main_file = [entry.msgid for entry in main_pot_file]

    something_changed = False
    for entry in yaml_pot_file:
        if entry.msgid in msgids_from_main_file:
            for main_entry in main_pot_file:
                if entry.msgid == main_entry.msgid:
                    for ref in entry.occurrences:
                        if ref not in main_entry.occurrences:
                            sys.stderr.write('Merging this entry: \n'
                                             + str(entry) + '\n')
                            previous_occ = main_entry.occurrences
                            main_entry.merge(entry)
                            main_entry.occurrences = list(
                                set(main_entry.occurrences) |
                                set(previous_occ))
                            something_changed = True
                            break
        else:
            sys.stderr.write('Adding new entry: \n' + str(entry) + '\n')
            main_pot_file.append(entry)
            something_changed = True

    msgids_from_yaml_pot_file = [entry.msgid for entry in yaml_pot_file]

    to_delete = []
    for main_entry in main_pot_file:
        o_to_delete = []
        for o in main_entry.occurrences:
            if (o[0][-5:] == '.yaml'
                and main_entry.msgid not in msgids_from_yaml_pot_file):
                o_to_delete.append(o)
                something_changed = True
        for o in o_to_delete:
            del main_entry.occurrences[main_entry.occurrences.index(o)]
            sys.stderr.write('Removed this obsolete occurrence: {} '
                             'from entry:\n{}\n'.format(o, main_entry))
        if not len(main_entry.occurrences):
            to_delete.append(main_entry)
            something_changed = True
            sys.stderr.write("Will remove this obsolete entry: \n"
                             + str(main_entry) + "\n")

    for entry in to_delete:
        del main_pot_file[main_pot_file.index(entry)]

    if something_changed:
        main_pot_file.save(args.filename)
    else:
        sys.stderr.write('No changes to save. ' + str(args.filename)
                         + ' remains unchanged.\n')

    sys.stdout.write('[merge_yaml_updates_to_pot_file] Done.\n\n')


if __name__ == '__main__':
    main()
